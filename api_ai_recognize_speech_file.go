// Code generated by lark_sdk_gen. DO NOT EDIT.

package lark

import (
	"context"
)

// RecognizeSpeechFile 语音文件识别接口，上传整段语音文件进行一次性识别。接口适合 60 秒以内音频识别
//
// 单租户限流：20QPS，同租户下的应用没有限流，共享本租户的 20QPS 限流
//
// doc: https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/reference/ai/speech_to_text-v1/speech/file_recognize
func (r *AIService) RecognizeSpeechFile(ctx context.Context, request *RecognizeSpeechFileReq, options ...MethodOptionFunc) (*RecognizeSpeechFileResp, *Response, error) {
	if r.cli.mock.mockAIRecognizeSpeechFile != nil {
		r.cli.logDebug(ctx, "[lark] AI#RecognizeSpeechFile mock enable")
		return r.cli.mock.mockAIRecognizeSpeechFile(ctx, request, options...)
	}

	r.cli.logInfo(ctx, "[lark] AI#RecognizeSpeechFile call api")
	r.cli.logDebug(ctx, "[lark] AI#RecognizeSpeechFile request: %s", jsonString(request))

	req := &RawRequestReq{
		Method:                "POST",
		URL:                   "https://open.feishu.cn/open-apis/speech_to_text/v1/speech/file_recognize",
		Body:                  request,
		MethodOption:          newMethodOption(options),
		NeedTenantAccessToken: true,
	}
	resp := new(recognizeSpeechFileResp)

	response, err := r.cli.RawRequest(ctx, req, resp)
	if err != nil {
		r.cli.logError(ctx, "[lark] AI#RecognizeSpeechFile POST https://open.feishu.cn/open-apis/speech_to_text/v1/speech/file_recognize failed: %s", err)
		return nil, response, err
	} else if resp.Code != 0 {
		r.cli.logError(ctx, "[lark] AI#RecognizeSpeechFile POST https://open.feishu.cn/open-apis/speech_to_text/v1/speech/file_recognize failed, code: %d, msg: %s", resp.Code, resp.Msg)
		return nil, response, NewError("AI", "RecognizeSpeechFile", resp.Code, resp.Msg)
	}

	r.cli.logDebug(ctx, "[lark] AI#RecognizeSpeechFile request_id: %s, response: %s", response.RequestID, jsonString(resp.Data))

	return resp.Data, response, nil
}

func (r *Mock) MockAIRecognizeSpeechFile(f func(ctx context.Context, request *RecognizeSpeechFileReq, options ...MethodOptionFunc) (*RecognizeSpeechFileResp, *Response, error)) {
	r.mockAIRecognizeSpeechFile = f
}

func (r *Mock) UnMockAIRecognizeSpeechFile() {
	r.mockAIRecognizeSpeechFile = nil
}

type RecognizeSpeechFileReq struct {
	Speech *RecognizeSpeechFileReqSpeech `json:"speech,omitempty"` // 语音资源
	Config *RecognizeSpeechFileReqConfig `json:"config,omitempty"` // 配置属性
}

type RecognizeSpeechFileReqSpeech struct {
	Speech    *string `json:"speech,omitempty"`     // base64 后的音频文件进行，和 speech_key 二选一, 示例值："base64 后的音频内容"
	SpeechKey *string `json:"speech_key,omitempty"` // 上传到 drive 存储平台后获取到的 key （暂不支持）, 示例值："xxxxxxxxxxx"
}

type RecognizeSpeechFileReqConfig struct {
	FileID     string `json:"file_id,omitempty"`     // 16 位 String 随机串作为文件的标识，用户生成, 示例值："qwe12dd34567890w"
	Format     string `json:"format,omitempty"`      // 语音格式，目前仅支持：pcm, 示例值："pcm"
	EngineType string `json:"engine_type,omitempty"` // 引擎类型，目前仅支持：16k_auto 中英混合, 示例值："16k_auto"
}

type recognizeSpeechFileResp struct {
	Code int                      `json:"code,omitempty"` // 错误码，非 0 表示失败
	Msg  string                   `json:"msg,omitempty"`  // 错误描述
	Data *RecognizeSpeechFileResp `json:"data,omitempty"` //
}

type RecognizeSpeechFileResp struct {
	RecognitionText string `json:"recognition_text,omitempty"` // 语音识别后的文本信息
}
